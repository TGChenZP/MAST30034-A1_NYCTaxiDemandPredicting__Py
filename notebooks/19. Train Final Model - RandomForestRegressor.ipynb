{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 15. Train Final Model: RandomForestRegressor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Import Data\n",
    "Train_data_X = pd.read_csv('../data/curated/ModelBuilding/Continuous/XTrain_16-1_16-5.csv')\n",
    "Train_data_y = pd.read_csv('../data/curated/ModelBuilding/Continuous/yTrain_16-1_16-5.csv')\n",
    "XTrain = Train_data_X\n",
    "yTrain = Train_data_y['count']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "Val_data_X = pd.read_csv('../data/curated/ModelBuilding/Continuous/XVal_16-5_16-6.csv')\n",
    "Val_data_y = pd.read_csv('../data/curated/ModelBuilding/Continuous/yVal_16-5_16-6.csv')\n",
    "XVal = Val_data_X\n",
    "yVal = Val_data_y['count']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "Test_data_X = pd.read_csv('../data/curated/ModelBuilding/Continuous/XTest_16-6_16-6.csv')\n",
    "Test_data_y = pd.read_csv('../data/curated/ModelBuilding/Continuous/yTest_16-6_16-6.csv')\n",
    "XTest = Test_data_X\n",
    "yTest = Test_data_y['count']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extra One Hot Encoding (On the Fly)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xg/8w_3dndd6l5c3n99vd7vd3f40000gn/T/ipykernel_8016/4070798213.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  XTrain[str(col)] = new_col\n",
      "/var/folders/xg/8w_3dndd6l5c3n99vd7vd3f40000gn/T/ipykernel_8016/4070798213.py:35: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  XVal[str(col)] = new_col\n",
      "/var/folders/xg/8w_3dndd6l5c3n99vd7vd3f40000gn/T/ipykernel_8016/4070798213.py:51: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  XTest[str(col)] = new_col\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# OHE for DOLocationID\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "Train_data_to_ohe = XTrain[['DOLocationID']]\n",
    "Train_data_ohe = ohe.fit_transform(Train_data_to_ohe).toarray()\n",
    "\n",
    "Train_data_ohe = pd.DataFrame(Train_data_ohe,\n",
    "                              columns=list(ohe.get_feature_names_out(['DOLocationID'])))\n",
    "\n",
    "XTrain = Train_data_X.drop(['DOLocationID'], axis=1)\n",
    "\n",
    "for col in Train_data_ohe.columns:\n",
    "    new_col = Train_data_ohe[col]\n",
    "    new_col.index = range(len(new_col))\n",
    "\n",
    "    XTrain[str(col)] = new_col\n",
    "\n",
    "\n",
    "\n",
    "Val_data_to_ohe = XVal[['DOLocationID']]\n",
    "Val_data_ohe = ohe.transform(Val_data_to_ohe).toarray()\n",
    "\n",
    "Val_data_ohe = pd.DataFrame(Val_data_ohe,\n",
    "                            columns=list(ohe.get_feature_names_out(['DOLocationID'])))\n",
    "\n",
    "XVal = XVal.drop(['DOLocationID'], axis=1)\n",
    "\n",
    "for col in Val_data_ohe.columns:\n",
    "    new_col = Val_data_ohe[col]\n",
    "    new_col.index = range(len(new_col))\n",
    "\n",
    "    XVal[str(col)] = new_col\n",
    "\n",
    "\n",
    "\n",
    "Test_data_to_ohe = XTest[['DOLocationID']]\n",
    "Test_data_ohe = ohe.transform(Test_data_to_ohe).toarray()\n",
    "\n",
    "Test_data_ohe = pd.DataFrame(Test_data_ohe,\n",
    "                             columns=list(ohe.get_feature_names_out(['DOLocationID'])))\n",
    "\n",
    "XTest = XTest.drop(['DOLocationID'], axis=1)\n",
    "\n",
    "for col in Test_data_ohe.columns:\n",
    "    new_col = Test_data_ohe[col]\n",
    "    new_col.index = range(len(new_col))\n",
    "\n",
    "    XTest[str(col)] = new_col"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xg/8w_3dndd6l5c3n99vd7vd3f40000gn/T/ipykernel_8016/3386760389.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  XTrain[str(col)] = new_col\n",
      "/var/folders/xg/8w_3dndd6l5c3n99vd7vd3f40000gn/T/ipykernel_8016/3386760389.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  XVal[str(col)] = new_col\n",
      "/var/folders/xg/8w_3dndd6l5c3n99vd7vd3f40000gn/T/ipykernel_8016/3386760389.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  XTest[str(col)] = new_col\n"
     ]
    }
   ],
   "source": [
    "# OHE for PULocationID\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "Train_data_to_ohe = XTrain[['PULocationID']]\n",
    "Train_data_ohe = ohe.fit_transform(Train_data_to_ohe).toarray()\n",
    "\n",
    "Train_data_ohe = pd.DataFrame(Train_data_ohe,\n",
    "                              columns=list(ohe.get_feature_names_out(['PULocationID'])))\n",
    "\n",
    "XTrain = XTrain.drop(['PULocationID'], axis=1)\n",
    "\n",
    "for col in Train_data_ohe.columns:\n",
    "    new_col = Train_data_ohe[col]\n",
    "    new_col.index = range(len(new_col))\n",
    "\n",
    "    XTrain[str(col)] = new_col\n",
    "\n",
    "\n",
    "\n",
    "Val_data_to_ohe = XVal[['PULocationID']]\n",
    "Val_data_ohe = ohe.transform(Val_data_to_ohe).toarray()\n",
    "\n",
    "Val_data_ohe = pd.DataFrame(Val_data_ohe,\n",
    "                            columns=list(ohe.get_feature_names_out(['PULocationID'])))\n",
    "\n",
    "XVal = XVal.drop(['PULocationID'], axis=1)\n",
    "\n",
    "for col in Val_data_ohe.columns:\n",
    "    new_col = Val_data_ohe[col]\n",
    "    new_col.index = range(len(new_col))\n",
    "\n",
    "    XVal[str(col)] = new_col\n",
    "\n",
    "\n",
    "\n",
    "Test_data_to_ohe = XTest[['PULocationID']]\n",
    "Test_data_ohe = ohe.transform(Test_data_to_ohe).toarray()\n",
    "\n",
    "Test_data_ohe = pd.DataFrame(Test_data_ohe,\n",
    "                             columns=list(ohe.get_feature_names_out(['PULocationID'])))\n",
    "\n",
    "XTest = XTest.drop(['PULocationID'], axis=1)\n",
    "\n",
    "for col in Test_data_ohe.columns:\n",
    "    new_col = Test_data_ohe[col]\n",
    "    new_col.index = range(len(new_col))\n",
    "\n",
    "    XTest[str(col)] = new_col"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "XTrain = XTrain.drop('datetime', axis=1)\n",
    "XVal = XVal.drop('datetime', axis=1)\n",
    "XTest = XTest.drop('datetime', axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train model and get statistics for each DOLocation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Initialise\n",
    "RF = RandomForestRegressor(n_estimators=50,\n",
    "                           max_depth = 60,\n",
    "                           max_samples = 0.75,\n",
    "                           ccp_alpha = 0.001)\n",
    "\n",
    "# Fit\n",
    "RF.fit(XTrain, yTrain)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get MSE, RMSE scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "Train_r2 = RF.score(XTrain, yTrain)\n",
    "Val_r2 = RF.score(XVal,yVal)\n",
    "Test_r2 = RF.score(XTest, yTest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359.0842058516159\n",
      "18.949517298644203\n"
     ]
    }
   ],
   "source": [
    "# Get the MSE data for the overall model\n",
    "\n",
    "# MSE has a deterministic relationship with variance and R2\n",
    "Full_Train_MSE = np.var(yTrain) * (len(yTrain)-1)*(1-Train_r2)/len(yTrain)\n",
    "print(Full_Train_MSE)\n",
    "print(np.sqrt(Full_Train_MSE))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344.7794558955399\n",
      "18.568237824186223\n"
     ]
    }
   ],
   "source": [
    "Full_Val_MSE = np.var(yVal) * (len(yVal)-1)*(1-Val_r2)/len(yVal)\n",
    "print(Full_Val_MSE)\n",
    "print(np.sqrt(Full_Val_MSE))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "332.6939324523404\n",
      "18.239899463877\n"
     ]
    }
   ],
   "source": [
    "Full_Test_MSE = np.var(yTest) * (len(yTrain)-1)*(1-Test_r2)/len(yTrain)\n",
    "print(Full_Test_MSE)\n",
    "print(np.sqrt(Full_Test_MSE))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Export object (and reopen, if don't want to have to rebuild the model every time)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create directory to store tuning results\n",
    "output_relative_dirs = ['../objects/Models']\n",
    "\n",
    "# check if it exists as it makedir will raise an error if it does exist\n",
    "for output_relative_dir in output_relative_dirs:\n",
    "    if not os.path.exists(output_relative_dir):\n",
    "        os.makedirs(output_relative_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../objects/models/rfr.pickle', 'wb') as f:\n",
    "    pickle.dump(RF,f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "with open('../objects/models/rfr.pickle', 'rb') as g:\n",
    "    object = pickle.load(g)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get statistics for each DOLocationID"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create list to store data to log\n",
    "id = list()\n",
    "TrainR2 = list()\n",
    "ValR2 = list()\n",
    "TestR2 = list()\n",
    "TrainCount = list()\n",
    "ValCount = list()\n",
    "TestCount = list()\n",
    "TrainMSE = list()\n",
    "ValMSE = list()\n",
    "TestMSE = list()\n",
    "\n",
    "for i in range(1, 264): # iterate through the DOLocations\n",
    "\n",
    "    print(i)\n",
    "    id.append(i)\n",
    "\n",
    "    # some DOLocation did not exist for training data so were never one hot encoded\n",
    "    if f'DOLocationID_{i}' in XTrain.columns:\n",
    "\n",
    "        # get the data for just in this Location\n",
    "\n",
    "        XTrain_subset = np.array(XTrain[XTrain[f'DOLocationID_{i}']==1])\n",
    "        yTrain_subset = np.array(yTrain[XTrain[f'DOLocationID_{i}']==1])\n",
    "\n",
    "        XVal_subset = np.array(XVal[XVal[f'DOLocationID_{i}']==1])\n",
    "        yVal_subset = np.array(yVal[XVal[f'DOLocationID_{i}']==1])\n",
    "\n",
    "        XTest_subset = np.array(XTest[XTest[f'DOLocationID_{i}']==1])\n",
    "        yTest_subset = np.array(yTest[XTest[f'DOLocationID_{i}']==1])\n",
    "\n",
    "        TrainCount.append(len(XTrain_subset))\n",
    "        ValCount.append(len(XVal_subset))\n",
    "        TestCount.append(len(XTest_subset))\n",
    "\n",
    "        # use tests to avoid errors when there are 0 samples\n",
    "        if len(XTrain_subset) > 0:\n",
    "            # make predictions\n",
    "            r2train = RF.score(XTrain_subset, yTrain_subset)\n",
    "            # get r^2 score and put it into list\n",
    "            TrainR2.append(r2train)\n",
    "\n",
    "            # get MSE (calculated from r^2 and variance)\n",
    "            varTrain = np.var(yTrain_subset)\n",
    "            TrainMSE.append( (1-r2train) * varTrain *(len(XTrain_subset)-1)/len(XTrain_subset) )\n",
    "\n",
    "        else:\n",
    "            # else append a placeholder to allow DataFrame construction later\n",
    "            TrainR2.append(np.nan)\n",
    "            TrainMSE.append(np.nan)\n",
    "\n",
    "\n",
    "        if len(XVal_subset) > 0:\n",
    "            # make predictions\n",
    "            r2val = RF.score(XVal_subset, yVal_subset)\n",
    "            # get r^2 score and put it into list\n",
    "            ValR2.append(r2val)\n",
    "\n",
    "            # get MSE (calculated from r^2 and variance)\n",
    "            varVal = np.var(yVal_subset)\n",
    "            ValMSE.append( (1-r2val) * varVal *(len(XVal_subset)-1)/len(XVal_subset) )\n",
    "\n",
    "        else:\n",
    "            # else append a placeholder to allow DataFrame construction later\n",
    "            ValR2.append(np.nan)\n",
    "            ValMSE.append(np.nan)\n",
    "\n",
    "\n",
    "        if len(XTest_subset) > 0:\n",
    "            # make predictions\n",
    "            r2test = RF.score(XTest_subset, yTest_subset)\n",
    "            # get r^2 score and put it into list\n",
    "            TestR2.append(r2test)\n",
    "\n",
    "            varTest = np.var(yTest_subset)\n",
    "            TestMSE.append( (1-r2test) * varTest * (len(XTest_subset)-1)/len(XTest_subset) )\n",
    "\n",
    "        else:\n",
    "            # else append a placeholder to allow DataFrame construction later\n",
    "            TestR2.append(np.nan)\n",
    "            TestMSE.append(np.nan)\n",
    "    else:\n",
    "        # else append a placeholder to allow DataFrame construction later\n",
    "        TrainR2.append(np.nan)\n",
    "        ValR2.append(np.nan)\n",
    "        TestR2.append(np.nan)\n",
    "        TrainCount.append(0)\n",
    "        ValCount.append(0)\n",
    "        TestCount.append(0)\n",
    "        TrainMSE.append(np.nan)\n",
    "        ValMSE.append(np.nan)\n",
    "        TestMSE.append(np.nan)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "# compile the statistics into a DataFrame\n",
    "r2_by_location = pd.DataFrame({'DOLocationID': id,\n",
    "                               'TrainR2': TrainR2,\n",
    "                               'ValR2': ValR2,\n",
    "                               'TestR2': TestR2,\n",
    "                               'TrainCount': TrainCount,\n",
    "                               'ValCount': ValCount,\n",
    "                               'TestCount': TestCount,\n",
    "                               'TrainMSE':TrainMSE,\n",
    "                               'ValMSE':ValMSE,\n",
    "                               'TestMSE':TestMSE})\n",
    "\n",
    "# Extra calculations to get root of mean squared error\n",
    "r2_by_location['TrainRMSE'] = np.sqrt(r2_by_location['TrainMSE'])\n",
    "r2_by_location['ValRMSE'] = np.sqrt(r2_by_location['ValMSE'])\n",
    "r2_by_location['TestRMSE'] = np.sqrt(r2_by_location['TestMSE'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "     DOLocationID   TrainR2     ValR2    TestR2  TrainCount  ValCount  \\\n0               1 -0.441874 -0.659623 -0.986344        2275       614   \n1               2       NaN       NaN       NaN           1         0   \n2               3       NaN       NaN       NaN           1         0   \n3               4  0.342235  0.358377  0.284629       11601      2239   \n4               5       NaN       NaN       NaN           0         0   \n..            ...       ...       ...       ...         ...       ...   \n258           259 -2.547365 -0.598803       NaN          12         3   \n259           260  0.028566  0.067271  0.163023        5949      1206   \n260           261  0.079921 -0.036524  0.048702       11092      2297   \n261           262  0.560703  0.520045  0.507581       21786      4421   \n262           263  0.466986  0.429463  0.435961       27419      5440   \n\n     TestCount    TrainMSE      ValMSE     TestMSE  TrainRMSE    ValRMSE  \\\n0          551   25.468107   20.084686   19.565782   5.046594   4.481594   \n1            0         NaN         NaN         NaN        NaN        NaN   \n2            0         NaN         NaN         NaN        NaN        NaN   \n3         1992  116.902115   84.192034   69.974149  10.812128   9.175622   \n4            0         NaN         NaN         NaN        NaN        NaN   \n..         ...         ...         ...         ...        ...        ...   \n258          1   16.507154   12.316702         NaN   4.062900   3.509516   \n259       1094   67.578899   60.688335   48.342623   8.220639   7.790272   \n260       2221   28.953577   25.470891   29.764111   5.380853   5.046869   \n261       4125  299.395279  288.084630  256.594274  17.303042  16.973056   \n262       5160  450.152591  433.773301  378.095379  21.216800  20.827225   \n\n      TestRMSE  \n0     4.423322  \n1          NaN  \n2          NaN  \n3     8.365055  \n4          NaN  \n..         ...  \n258        NaN  \n259   6.952886  \n260   5.455649  \n261  16.018560  \n262  19.444675  \n\n[263 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DOLocationID</th>\n      <th>TrainR2</th>\n      <th>ValR2</th>\n      <th>TestR2</th>\n      <th>TrainCount</th>\n      <th>ValCount</th>\n      <th>TestCount</th>\n      <th>TrainMSE</th>\n      <th>ValMSE</th>\n      <th>TestMSE</th>\n      <th>TrainRMSE</th>\n      <th>ValRMSE</th>\n      <th>TestRMSE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>-0.441874</td>\n      <td>-0.659623</td>\n      <td>-0.986344</td>\n      <td>2275</td>\n      <td>614</td>\n      <td>551</td>\n      <td>25.468107</td>\n      <td>20.084686</td>\n      <td>19.565782</td>\n      <td>5.046594</td>\n      <td>4.481594</td>\n      <td>4.423322</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.342235</td>\n      <td>0.358377</td>\n      <td>0.284629</td>\n      <td>11601</td>\n      <td>2239</td>\n      <td>1992</td>\n      <td>116.902115</td>\n      <td>84.192034</td>\n      <td>69.974149</td>\n      <td>10.812128</td>\n      <td>9.175622</td>\n      <td>8.365055</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>258</th>\n      <td>259</td>\n      <td>-2.547365</td>\n      <td>-0.598803</td>\n      <td>NaN</td>\n      <td>12</td>\n      <td>3</td>\n      <td>1</td>\n      <td>16.507154</td>\n      <td>12.316702</td>\n      <td>NaN</td>\n      <td>4.062900</td>\n      <td>3.509516</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>259</th>\n      <td>260</td>\n      <td>0.028566</td>\n      <td>0.067271</td>\n      <td>0.163023</td>\n      <td>5949</td>\n      <td>1206</td>\n      <td>1094</td>\n      <td>67.578899</td>\n      <td>60.688335</td>\n      <td>48.342623</td>\n      <td>8.220639</td>\n      <td>7.790272</td>\n      <td>6.952886</td>\n    </tr>\n    <tr>\n      <th>260</th>\n      <td>261</td>\n      <td>0.079921</td>\n      <td>-0.036524</td>\n      <td>0.048702</td>\n      <td>11092</td>\n      <td>2297</td>\n      <td>2221</td>\n      <td>28.953577</td>\n      <td>25.470891</td>\n      <td>29.764111</td>\n      <td>5.380853</td>\n      <td>5.046869</td>\n      <td>5.455649</td>\n    </tr>\n    <tr>\n      <th>261</th>\n      <td>262</td>\n      <td>0.560703</td>\n      <td>0.520045</td>\n      <td>0.507581</td>\n      <td>21786</td>\n      <td>4421</td>\n      <td>4125</td>\n      <td>299.395279</td>\n      <td>288.084630</td>\n      <td>256.594274</td>\n      <td>17.303042</td>\n      <td>16.973056</td>\n      <td>16.018560</td>\n    </tr>\n    <tr>\n      <th>262</th>\n      <td>263</td>\n      <td>0.466986</td>\n      <td>0.429463</td>\n      <td>0.435961</td>\n      <td>27419</td>\n      <td>5440</td>\n      <td>5160</td>\n      <td>450.152591</td>\n      <td>433.773301</td>\n      <td>378.095379</td>\n      <td>21.216800</td>\n      <td>20.827225</td>\n      <td>19.444675</td>\n    </tr>\n  </tbody>\n</table>\n<p>263 rows Ã— 13 columns</p>\n</div>"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_by_location"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Export statistics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "# create directory to store models results\n",
    "output_relative_dirs = ['../data/curated/final_model_data']\n",
    "\n",
    "# check if it exists as it makedir will raise an error if it does exist\n",
    "for output_relative_dir in output_relative_dirs:\n",
    "    if not os.path.exists(output_relative_dir):\n",
    "        os.makedirs(output_relative_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "r2_by_location.to_csv('../data/curated/final_model_data/rfr.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}