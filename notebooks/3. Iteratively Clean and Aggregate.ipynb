{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Iteratively Clean and Aggregate\n",
    "\n",
    "### *NOTE: could have functionalised clean; but because certain column names different, was just more convenient to copy and paste - more convenient to use and time efficient*"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/08 16:26:36 WARN Utils: Your hostname, modaxuexiweiyuanzhangde-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.3.59 instead (on interface en0)\n",
      "22/08/08 16:26:36 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/08 16:26:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/08/08 16:26:38 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Create a spark session (which will run spark jobs)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Tutorial 1\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .getOrCreate()\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# create new directory\n",
    "output_relative_dirs = ['../data/curated/taxi_aggregated',\n",
    "                        '../data/curated/taxi_parquet']\n",
    "\n",
    "# check if it exists as it makedir will raise an error if it does exist\n",
    "for output_relative_dir in output_relative_dirs:\n",
    "    if not os.path.exists(output_relative_dir):\n",
    "        os.makedirs(output_relative_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Green**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "['2016-01.parquet',\n '2016-02.parquet',\n '2016-03.parquet',\n '2016-04.parquet',\n '2016-05.parquet',\n '2016-06.parquet']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect list of raw files to clean\n",
    "to_clean_green = sorted(os.listdir('../data/raw/NYC_Taxi/green'))[1:]\n",
    "to_clean_green"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1445292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                          (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/08 16:21:16 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "22/08/08 16:21:16 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "22/08/08 16:21:18 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1510722\n",
      "8328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:================================================>         (5 + 1) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/08 16:21:55 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "22/08/08 16:21:55 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/08 16:21:56 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1576393\n",
      "8321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 33:================================================>         (5 + 1) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/08 16:22:31 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "22/08/08 16:22:31 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/08 16:22:32 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1543926\n",
      "8547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 46:================================================>         (5 + 1) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/08 16:23:09 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "22/08/08 16:23:09 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "22/08/08 16:23:10 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536979\n",
      "8272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 59:================================================>         (5 + 1) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/08 16:23:46 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "22/08/08 16:23:46 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "22/08/08 16:23:47 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1404727\n",
      "7306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 72:================================================>         (5 + 1) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/08 16:24:24 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n",
      "22/08/08 16:24:24 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 84.47% for 8 writers\n",
      "22/08/08 16:24:24 WARN MemoryManager: Total allocation exceeds 95.00% (906,992,014 bytes) of heap memory\n",
      "Scaling row group sizes to 96.54% for 7 writers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# set schema\n",
    "ddl_green = \"\"\"VendorID int,\n",
    "lpep_pickup_datetime datetime,\n",
    "lpep_dropoff_datetime datetime,\n",
    "store_and_fwd_flag string,\n",
    "RatecodeID int,\n",
    "PULocationID int,\n",
    "DOLocationID int,\n",
    "passenger_count int,\n",
    "trip_distance double,\n",
    "fare_amount double,\n",
    "extra double,\n",
    "mta_tax double,\n",
    "tip_amount double,\n",
    "tolls_amount double,\n",
    "ehail_fee double,\n",
    "improvement_surcharge double,\n",
    "total_amount double,\n",
    "payment_type int,\n",
    "trip_type int,\n",
    "congestion_surcharge double\"\"\"\n",
    "\n",
    "# iteratively remove outlier and aggregate each file\n",
    "for file in to_clean_green:\n",
    "    if '2016-01' in file or '2016-02' in file or '2016-03' in file or '2016-04' in file or \\\n",
    "            '2016-05' in file or '2016-06' in file:\n",
    "\n",
    "        sdf_taxi = spark.read.parquet(f'../data/raw/NYC_Taxi/green/{file}', schema = ddl_green)\n",
    "\n",
    "        # engineer features: for determining whether trip duration ws strictly positive\n",
    "        sdf_taxi = sdf_taxi.withColumn(\"lpep_pickup_datetime\",\n",
    "             to_timestamp(col(\"lpep_pickup_datetime\"),\"MM-dd-yyyy HH:mm:ss\"))\n",
    "        sdf_taxi = sdf_taxi.withColumn(\"lpep_dropoff_datetime\",\n",
    "             to_timestamp(col(\"lpep_dropoff_datetime\"),\"MM-dd-yyyy HH:mm:ss\"))\n",
    "        sdf_taxi = sdf_taxi.withColumn(\"trip_duration\",\n",
    "                                       col(\"lpep_dropoff_datetime\")>col('lpep_pickup_datetime'))\n",
    "\n",
    "        # drop outliers: non positive trip duration; locationID error; date outside correct range\n",
    "        sdf_taxi_wo_outliers = sdf_taxi.filter((col('PULocationID') <= 263) &\n",
    "                                               (col('PULocationID') >= 1) &\n",
    "                                               (col('DOLocationID') <= 263) &\n",
    "                                               (col('DOLocationID') >=  1)).filter(col('trip_duration') == True).filter((col(\"lpep_pickup_datetime\") >= unix_timestamp(lit('2016-01-01 00:00:00')).cast('timestamp')) &\n",
    "                                                (col(\"lpep_pickup_datetime\") <= unix_timestamp(lit('2019-12-31 00:00:00')).cast('timestamp')))\n",
    "\n",
    "        # drop useless rows - save space when saving\n",
    "        sdf_taxi_wo_outliers = sdf_taxi_wo_outliers.drop('store_and_fwd_flag', 'passenger_count',\n",
    "                                                         'lpep_dropoff_datetime', 'trip_distance',\n",
    "                                                         'store_and_fwd_flag', 'payment_type',\n",
    "                                                         'fare_amount', 'extra', 'mta_tax',\n",
    "                                                         'mta_tax', 'tolls_amount',\n",
    "                                                         'improvement_surcharge', 'total_amount',\n",
    "                                                         'trip_duration', 'VendorID', 'tip_amount')\n",
    "\n",
    "        # for counting up how many rows were removed in report\n",
    "        length = sdf_taxi.count()\n",
    "        print(length)\n",
    "        print(length - sdf_taxi_wo_outliers.count())\n",
    "\n",
    "        # aggregation\n",
    "        sdf_groupby = sdf_taxi_wo_outliers.groupBy([date_trunc('hour',\n",
    "                                                    col('lpep_pickup_datetime')).alias('rounded_lepep_pickup_datetime'),\n",
    "                                                    'DOLocationID', 'PULocationID']).count()\n",
    "        sdf_groupby = sdf_groupby.withColumn(\"weekday\", date_format('rounded_lepep_pickup_datetime', 'EEEE'))\n",
    "        sdf_groupby = sdf_groupby.withColumn(\"hour\", date_format('rounded_lepep_pickup_datetime', 'HH'))\n",
    "\n",
    "        # output\n",
    "        sdf_groupby.toPandas().to_csv(f'../data/curated/taxi_aggregated/green_{file.split(\".\")[0]}.csv', index = False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Yellow**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "['2016-01.parquet',\n '2016-02.parquet',\n '2016-03.parquet',\n '2016-04.parquet',\n '2016-05.parquet',\n '2016-06.parquet']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collect list of raw files to clean\n",
    "to_clean_yellow = sorted(os.listdir('../data/raw/NYC_Taxi/yellow'))[1:]\n",
    "to_clean_yellow"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10905067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11375412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12203824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11927996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11832049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11131645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# set schema\n",
    "ddl_yellow = [\"\"\"VendorID int,\n",
    "              tpep_pickup_datetime datetime,\n",
    "              tpep_dropoff_datetime datetime,\n",
    "              passenger_count int,\n",
    "              trip_distance double,\n",
    "              RatecodeID int,\n",
    "              store_and_fwd_flag string,\n",
    "              PULocationID int,\n",
    "              DOLocationID int,\n",
    "              payment_type double,\n",
    "              fare_amount double,\n",
    "              extra double,\n",
    "              mta_tax double,\n",
    "              tip_amount double,\n",
    "              tolls_amount double,\n",
    "              improvement_surcharge double,\n",
    "              total_amount double,\n",
    "              congestion_surcharge double,\n",
    "              airport_fee double\"\"\"]\n",
    "\n",
    "# iteratively remove outlier and aggregate each file\n",
    "for file in to_clean_yellow:\n",
    "    if '2016-01' in file or '2016-02' in file or '2016-03' in file or \\\n",
    "            '2016-04' in file or '2016-05' in file or '2016-06' in file:\n",
    "\n",
    "        sdf_taxi = spark.read.parquet(f'../data/raw/NYC_Taxi/yellow/{file}', schema = ddl_yellow)\n",
    "\n",
    "        # engineer features: for determining whether trip duration ws strictly positive\n",
    "        sdf_taxi = sdf_taxi.withColumnRenamed('tpep_pickup_datetime',\n",
    "                                              'lpep_pickup_datetime').withColumnRenamed('tpep_dropoff_datetime',\n",
    "                                                                                        'lpep_dropoff_datetime')\n",
    "        sdf_taxi = sdf_taxi.withColumn(\"lpep_pickup_datetime\",\n",
    "             to_timestamp(col(\"lpep_pickup_datetime\"),\"MM-dd-yyyy HH:mm:ss\"))\n",
    "        sdf_taxi = sdf_taxi.withColumn(\"lpep_dropoff_datetime\",\n",
    "             to_timestamp(col(\"lpep_dropoff_datetime\"),\"MM-dd-yyyy HH:mm:ss\"))\n",
    "        sdf_taxi = sdf_taxi.withColumn(\"trip_duration\",\n",
    "                                       col(\"lpep_dropoff_datetime\")>col('lpep_pickup_datetime'))\n",
    "\n",
    "        # drop outliers: non positive trip duration; locationID error; date outside correct range\n",
    "        sdf_taxi_wo_outliers = sdf_taxi.filter((col('PULocationID') <= 263) &\n",
    "                                               (col('PULocationID') >= 1) &\n",
    "                                               (col('DOLocationID') <= 263) &\n",
    "                                               (col('DOLocationID') >=  1)).filter(col('trip_duration') == True).filter((col(\"lpep_pickup_datetime\") >= unix_timestamp(lit('2016-01-01 00:00:00')).cast('timestamp')) &\n",
    "                                                (col(\"lpep_pickup_datetime\") <= unix_timestamp(lit('2019-12-31 00:00:00')).cast('timestamp')))\n",
    "\n",
    "        # drop useless rows - save space when saving\n",
    "        sdf_taxi_wo_outliers = sdf_taxi_wo_outliers.drop('store_and_fwd_flag', 'passenger_count',\n",
    "                                                         'lpep_dropoff_datetime', 'trip_distance',\n",
    "                                                         'store_and_fwd_flag', 'payment_type',\n",
    "                                                         'fare_amount', 'extra', 'mta_tax', 'mta_tax',\n",
    "                                                         'tolls_amount', 'improvement_surcharge',\n",
    "                                                         'total_amount', 'trip_duration',\n",
    "                                                         'VendorID', 'tip_amount')\n",
    "\n",
    "        # for counting up how many rows were removed in report\n",
    "        length = sdf_taxi.count()\n",
    "        print(length)\n",
    "        print(length - sdf_taxi_wo_outliers.count())\n",
    "\n",
    "        # aggregation\n",
    "        sdf_groupby = sdf_taxi_wo_outliers.groupBy([date_trunc('hour',\n",
    "                                                    col('lpep_pickup_datetime')).alias('rounded_lepep_pickup_datetime'),\n",
    "                                                    'DOLocationID', 'PULocationID']).count()\n",
    "        sdf_groupby = sdf_groupby.withColumn(\"weekday\", date_format('rounded_lepep_pickup_datetime', 'EEEE'))\n",
    "        sdf_groupby = sdf_groupby.withColumn(\"hour\", date_format('rounded_lepep_pickup_datetime', 'HH'))\n",
    "\n",
    "        # output\n",
    "        sdf_groupby.toPandas().to_csv(f'../data/curated/taxi_aggregated/yellow_{file.split(\".\")[0]}.csv', index = False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}