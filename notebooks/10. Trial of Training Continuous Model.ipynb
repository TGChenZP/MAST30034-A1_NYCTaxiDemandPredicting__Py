{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 10. Trial of Training Continuous Model\n",
    "\n",
    "- Trains a selection of predictive models with default hyperparameter values to gauge the time required to train-score one model, and also get a preview of the R^2 scores\n",
    "- notebook follows Initialise, Train, Predict, Get Accuracy Score steps"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "Train_data_X = pd.read_csv('../data/curated/ModelBuilding/Continuous/XTrain_16-1_16-5.csv')\n",
    "Train_data_y = pd.read_csv('../data/curated/ModelBuilding/Continuous/yTrain_16-1_16-5.csv')\n",
    "XTrain = Train_data_X.drop(['datetime'], axis=1)\n",
    "yTrain = Train_data_y['count']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "Val_data_X = pd.read_csv('../data/curated/ModelBuilding/Continuous/XVal_16-5_16-6.csv')\n",
    "Val_data_y = pd.read_csv('../data/curated/ModelBuilding/Continuous/yVal_16-5_16-6.csv')\n",
    "XVal = Val_data_X.drop(['datetime'], axis=1)\n",
    "yVal = Val_data_y['count']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "Test_data_X = pd.read_csv('../data/curated/ModelBuilding/Continuous/XTest_16-6_16-6.csv')\n",
    "Test_data_y = pd.read_csv('../data/curated/ModelBuilding/Continuous/yTest_16-6_16-6.csv')\n",
    "XTest = Test_data_X.drop(['datetime'], axis=1)\n",
    "yTest = Test_data_y['count']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extra One Hot Encoding (on the fly)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xg/8w_3dndd6l5c3n99vd7vd3f40000gn/T/ipykernel_7283/2939088732.py:17: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  XTrain[str(col)] = new_col\n",
      "/var/folders/xg/8w_3dndd6l5c3n99vd7vd3f40000gn/T/ipykernel_7283/2939088732.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  XVal[str(col)] = new_col\n",
      "/var/folders/xg/8w_3dndd6l5c3n99vd7vd3f40000gn/T/ipykernel_7283/2939088732.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  XTest[str(col)] = new_col\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# OHE for DOLocationID\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "Train_data_to_ohe = XTrain[['DOLocationID']]\n",
    "Train_data_ohe = ohe.fit_transform(Train_data_to_ohe).toarray()\n",
    "\n",
    "Train_data_ohe = pd.DataFrame(Train_data_ohe,\n",
    "                              columns=list(ohe.get_feature_names_out(['DOLocationID'])))\n",
    "\n",
    "XTrain = Train_data_X.drop(['DOLocationID'], axis=1)\n",
    "\n",
    "for col in Train_data_ohe.columns:\n",
    "    new_col = Train_data_ohe[col]\n",
    "    new_col.index = range(len(new_col))\n",
    "\n",
    "    XTrain[str(col)] = new_col\n",
    "\n",
    "\n",
    "\n",
    "Val_data_to_ohe = XVal[['DOLocationID']]\n",
    "Val_data_ohe = ohe.transform(Val_data_to_ohe).toarray()\n",
    "\n",
    "Val_data_ohe = pd.DataFrame(Val_data_ohe,\n",
    "                            columns=list(ohe.get_feature_names_out(['DOLocationID'])))\n",
    "\n",
    "XVal = XVal.drop(['DOLocationID'], axis=1)\n",
    "\n",
    "for col in Val_data_ohe.columns:\n",
    "    new_col = Val_data_ohe[col]\n",
    "    new_col.index = range(len(new_col))\n",
    "\n",
    "    XVal[str(col)] = new_col\n",
    "\n",
    "\n",
    "\n",
    "Test_data_to_ohe = XTest[['DOLocationID']]\n",
    "Test_data_ohe = ohe.transform(Test_data_to_ohe).toarray()\n",
    "\n",
    "Test_data_ohe = pd.DataFrame(Test_data_ohe,\n",
    "                             columns=list(ohe.get_feature_names_out(['DOLocationID'])))\n",
    "\n",
    "XTest = XTest.drop(['DOLocationID'], axis=1)\n",
    "\n",
    "for col in Test_data_ohe.columns:\n",
    "    new_col = Test_data_ohe[col]\n",
    "    new_col.index = range(len(new_col))\n",
    "\n",
    "    XTest[str(col)] = new_col"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xg/8w_3dndd6l5c3n99vd7vd3f40000gn/T/ipykernel_7283/2332929001.py:14: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  XTrain[str(col)] = new_col\n",
      "/var/folders/xg/8w_3dndd6l5c3n99vd7vd3f40000gn/T/ipykernel_7283/2332929001.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  XVal[str(col)] = new_col\n",
      "/var/folders/xg/8w_3dndd6l5c3n99vd7vd3f40000gn/T/ipykernel_7283/2332929001.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  XTest[str(col)] = new_col\n"
     ]
    }
   ],
   "source": [
    "# OHE for PULocationID\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "Train_data_to_ohe = XTrain[['PULocationID']]\n",
    "Train_data_ohe = ohe.fit_transform(Train_data_to_ohe).toarray()\n",
    "\n",
    "Train_data_ohe = pd.DataFrame(Train_data_ohe,\n",
    "                              columns=list(ohe.get_feature_names_out(['PULocationID'])))\n",
    "\n",
    "XTrain = XTrain.drop(['PULocationID'], axis=1)\n",
    "\n",
    "for col in Train_data_ohe.columns:\n",
    "    new_col = Train_data_ohe[col]\n",
    "    new_col.index = range(len(new_col))\n",
    "\n",
    "    XTrain[str(col)] = new_col\n",
    "\n",
    "\n",
    "\n",
    "Val_data_to_ohe = XVal[['PULocationID']]\n",
    "Val_data_ohe = ohe.transform(Val_data_to_ohe).toarray()\n",
    "\n",
    "Val_data_ohe = pd.DataFrame(Val_data_ohe,\n",
    "                            columns=list(ohe.get_feature_names_out(['PULocationID'])))\n",
    "\n",
    "XVal = XVal.drop(['PULocationID'], axis=1)\n",
    "\n",
    "for col in Val_data_ohe.columns:\n",
    "    new_col = Val_data_ohe[col]\n",
    "    new_col.index = range(len(new_col))\n",
    "\n",
    "    XVal[str(col)] = new_col\n",
    "\n",
    "\n",
    "\n",
    "Test_data_to_ohe = XTest[['PULocationID']]\n",
    "Test_data_ohe = ohe.transform(Test_data_to_ohe).toarray()\n",
    "\n",
    "Test_data_ohe = pd.DataFrame(Test_data_ohe,\n",
    "                             columns=list(ohe.get_feature_names_out(['PULocationID'])))\n",
    "\n",
    "XTest = XTest.drop(['PULocationID'], axis=1)\n",
    "\n",
    "for col in Test_data_ohe.columns:\n",
    "    new_col = Test_data_ohe[col]\n",
    "    new_col.index = range(len(new_col))\n",
    "\n",
    "    XTest[str(col)] = new_col"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "XTrain = XTrain.drop('datetime', axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Models\n",
    "## 0R (manual - alwasy predict mean)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "26.353318895400452"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get mean\n",
    "mean_y = np.mean(yTrain)\n",
    "mean_y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875.406278659021\n",
      "29.5872654812678\n"
     ]
    }
   ],
   "source": [
    "# get the MSE and sd of null model (always predict mean)\n",
    "ZeroR_MSE = sum((yTrain-mean_y)**2)/len(yTrain)\n",
    "print(ZeroR_MSE)\n",
    "print(np.sqrt(ZeroR_MSE))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "772.1266870677043\n",
      "27.78716766904652\n"
     ]
    }
   ],
   "source": [
    "# Validation R^2\n",
    "ZeroR_MSE_val = sum((yVal - mean_y) ** 2) / len(yVal)\n",
    "print(ZeroR_MSE_val)\n",
    "print(np.sqrt(ZeroR_MSE_val))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742.2973997260035\n",
      "27.2451353405705\n"
     ]
    }
   ],
   "source": [
    "# Test R^2\n",
    "ZeroR_MSE_test = sum((yTest-mean_y)**2)/len(yTest)\n",
    "print(ZeroR_MSE_test)\n",
    "print(np.sqrt(ZeroR_MSE_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## RFRegressor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Initialise and Fit\n",
    "RF = RandomForestRegressor(n_estimators = 100, max_depth=16)\n",
    "RF.fit(XTrain, yTrain)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Predict and score for train\n",
    "train_pred_RF = RF.predict(XTrain)\n",
    "RF.score(XTrain, yTrain)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Predict and score for validation\n",
    "val_pred_RF = RF.predict(XVal)\n",
    "RF.score(XVal, yVal)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Predict and score for test\n",
    "test_pred_RF = RF.predict(XTest)\n",
    "RF.score(XTest, yTest)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}