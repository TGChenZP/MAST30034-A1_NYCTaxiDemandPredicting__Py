{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 14. Train Final Model: LogReg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Import Data\n",
    "Train_data_X = pd.read_csv('../data/curated/ModelBuilding/Discrete/XTrain_16-1_16-5.csv')\n",
    "Train_data_y = pd.read_csv('../data/curated/ModelBuilding/Discrete/yTrain_16-1_16-5.csv')\n",
    "XTrain = Train_data_X\n",
    "yTrain = Train_data_y['Max_PULocationID']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "Val_data_X = pd.read_csv('../data/curated/ModelBuilding/Discrete/XVal_16-5_16-6.csv')\n",
    "Val_data_y = pd.read_csv('../data/curated/ModelBuilding/Discrete/yVal_16-5_16-6.csv')\n",
    "XVal = Val_data_X\n",
    "yVal = Val_data_y['Max_PULocationID']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "Test_data_X = pd.read_csv('../data/curated/ModelBuilding/Discrete/XTest_16-6_16-6.csv')\n",
    "Test_data_y = pd.read_csv('../data/curated/ModelBuilding/Discrete/yTest_16-6_16-6.csv')\n",
    "XTest = Test_data_X\n",
    "yTest = Test_data_y['Max_PULocationID']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extra One Hot Encoding (On the Fly)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xg/8w_3dndd6l5c3n99vd7vd3f40000gn/T/ipykernel_8485/2543678202.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  XTrain[str(col)] = new_col\n",
      "/var/folders/xg/8w_3dndd6l5c3n99vd7vd3f40000gn/T/ipykernel_8485/2543678202.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  XVal[str(col)] = new_col\n",
      "/var/folders/xg/8w_3dndd6l5c3n99vd7vd3f40000gn/T/ipykernel_8485/2543678202.py:55: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  XTest[str(col)] = new_col\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# OHE for DOLocationID\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "Train_data_to_ohe = XTrain[['DOLocationID']]\n",
    "Train_data_ohe = ohe.fit_transform(Train_data_to_ohe).toarray()\n",
    "\n",
    "Train_data_ohe = pd.DataFrame(Train_data_ohe,\n",
    "                              columns=list(ohe.get_feature_names_out(['DOLocationID'])))\n",
    "\n",
    "XTrain = Train_data_X.drop(['DOLocationID'], axis=1)\n",
    "\n",
    "for col in Train_data_ohe.columns:\n",
    "    new_col = Train_data_ohe[col]\n",
    "    new_col.index = range(len(new_col))\n",
    "\n",
    "    XTrain[str(col)] = new_col\n",
    "\n",
    "XTrain = XTrain.drop('datetime', axis=1)\n",
    "\n",
    "\n",
    "\n",
    "Val_data_to_ohe = XVal[['DOLocationID']]\n",
    "Val_data_ohe = ohe.transform(Val_data_to_ohe).toarray()\n",
    "\n",
    "Val_data_ohe = pd.DataFrame(Val_data_ohe,\n",
    "                            columns=list(ohe.get_feature_names_out(['DOLocationID'])))\n",
    "\n",
    "XVal = XVal.drop(['DOLocationID'], axis=1)\n",
    "\n",
    "for col in Val_data_ohe.columns:\n",
    "    new_col = Val_data_ohe[col]\n",
    "    new_col.index = range(len(new_col))\n",
    "\n",
    "    XVal[str(col)] = new_col\n",
    "\n",
    "XVal = XVal.drop('datetime', axis=1)\n",
    "\n",
    "\n",
    "\n",
    "Test_data_to_ohe = XTest[['DOLocationID']]\n",
    "Test_data_ohe = ohe.transform(Test_data_to_ohe).toarray()\n",
    "\n",
    "Test_data_ohe = pd.DataFrame(Test_data_ohe,\n",
    "                             columns=list(ohe.get_feature_names_out(['DOLocationID'])))\n",
    "\n",
    "XTest = XTest.drop(['DOLocationID'], axis=1)\n",
    "\n",
    "for col in Test_data_ohe.columns:\n",
    "    new_col = Test_data_ohe[col]\n",
    "    new_col.index = range(len(new_col))\n",
    "\n",
    "    XTest[str(col)] = new_col\n",
    "\n",
    "XTest = XTest.drop('datetime', axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Special format for getting data in right format for accuracy evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# read lists stored as a string in csv and re-establish as lists\n",
    "train_obs = [[int(x) for x in Max_IDs.strip('[]').split(',')] for Max_IDs in Train_data_y['Max_PULocationIDs']]\n",
    "val_obs = [[int(x) for x in Max_IDs.strip('[]').split(',')] for Max_IDs in Val_data_y['Max_PULocationIDs']]\n",
    "test_obs = [[int(x) for x in Max_IDs.strip('[]').split(',')] for Max_IDs in Test_data_y['Max_PULocationIDs']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def accuracy_score(pred, obs):\n",
    "    \"\"\" Helper function to get accuracy score for multiple correct labels \"\"\"\n",
    "    n = len(pred)\n",
    "    n_tp = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        if pred[i] in obs[i]:\n",
    "            n_tp += 1\n",
    "\n",
    "    return n_tp/n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train model and get statistics for each DOLocation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegression(C=10, max_iter=100000, solver='newton-cg')"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialise\n",
    "logR = LogisticRegression(C = 10,\n",
    "                          solver = 'newton-cg',\n",
    "                          penalty = 'l2',\n",
    "                          max_iter = 100000)\n",
    "\n",
    "# Fit\n",
    "logR.fit(XTrain, yTrain)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Export object (and reopen, if don't want to have to rebuild the model every time)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# create directory to store tuning results\n",
    "output_relative_dirs = ['../objects/models']\n",
    "\n",
    "# check if it exists as it makedir will\n",
    "# raise an error if it does exist\n",
    "for output_relative_dir in output_relative_dirs:\n",
    "    if not os.path.exists(output_relative_dir):\n",
    "        os.makedirs(output_relative_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../objects/models/logreg.pickle', 'wb') as f:\n",
    "    pickle.dump(logR,f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "with open('../objects/models/logreg.pickle', 'rb') as g:\n",
    "    object = pickle.load(g)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get statistics for each DOLocationID"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n"
     ]
    }
   ],
   "source": [
    "# create list to store data to log\n",
    "id = list()\n",
    "TrainAccu = list()\n",
    "ValAccu = list()\n",
    "TestAccu = list()\n",
    "TrainCount = list()\n",
    "ValCount = list()\n",
    "TestCount = list()\n",
    "\n",
    "\n",
    "for i in range(1, 264): # iterate through the DOLocations\n",
    "\n",
    "    print(i)\n",
    "    id.append(i)\n",
    "\n",
    "    # some DOLocation did not exist for training data\n",
    "    # so were never one hot encoded\n",
    "    if f'DOLocationID_{i}.0' in XTrain.columns:\n",
    "\n",
    "        # get the data for just in this Location\n",
    "\n",
    "        XTrain_subset = XTrain[XTrain[f'DOLocationID_{i}.0']==1]\n",
    "        yTrain_subset = Train_data_y[XTrain[f'DOLocationID_{i}.0']==1]\n",
    "\n",
    "        XVal_subset = XVal[XVal[f'DOLocationID_{i}.0']==1]\n",
    "        yVal_subset = Val_data_y[XVal[f'DOLocationID_{i}.0']==1]\n",
    "\n",
    "        XTest_subset = XTest[XTest[f'DOLocationID_{i}.0']==1]\n",
    "        yTest_subset = Test_data_y[XTest[f'DOLocationID_{i}.0']==1]\n",
    "\n",
    "        # preprocess data required for accuracy test with\n",
    "        # multiple correct labels (just for this DOL subsample)\n",
    "        train_obs_subset = [[int(x) for x in Max_IDs.strip('[]').split(',')]\n",
    "                            for Max_IDs in yTrain_subset['Max_PULocationIDs']]\n",
    "        val_obs_subset = [[int(x) for x in Max_IDs.strip('[]').split(',')]\n",
    "                          for Max_IDs in yVal_subset['Max_PULocationIDs']]\n",
    "        test_obs_subset = [[int(x) for x in Max_IDs.strip('[]').split(',')]\n",
    "                           for Max_IDs in yTest_subset['Max_PULocationIDs']]\n",
    "\n",
    "        TrainCount.append(len(XTrain_subset))\n",
    "        ValCount.append(len(XVal_subset))\n",
    "        TestCount.append(len(XTest_subset))\n",
    "\n",
    "\n",
    "        # use tests to avoid errors when there are 0 samples\n",
    "        if len(XTrain_subset) > 0:\n",
    "            # make predictions\n",
    "            predTrain_subset = logR.predict(XTrain_subset)\n",
    "            # get accuracy score and put it into list\n",
    "            TrainAccu.append(accuracy_score(predTrain_subset, train_obs_subset))\n",
    "        else:\n",
    "            # else append a placeholder to allow DataFrame construction later\n",
    "            TrainAccu.append(-1)\n",
    "\n",
    "        # use tests to avoid errors when there are 0 samples\n",
    "        if len(XVal_subset) > 0:\n",
    "            # make predictions\n",
    "            predVal_subset = logR.predict(XVal_subset)\n",
    "            # get accuracy score and put it into list\n",
    "            ValAccu.append(accuracy_score(predVal_subset, val_obs_subset))\n",
    "        else:\n",
    "            # else append a placeholder to allow DataFrame construction later\n",
    "            ValAccu.append(-1)\n",
    "\n",
    "        # use tests to avoid errors when there are 0 samples\n",
    "        if len(XTest_subset) > 0:\n",
    "            # make predictions\n",
    "            predTest_subset = logR.predict(XTest_subset)\n",
    "            # get accuracy score and put it into list\n",
    "            TestAccu.append(accuracy_score(predTest_subset, test_obs_subset))\n",
    "        else:\n",
    "            # else append a placeholder to allow DataFrame construction later\n",
    "            TestAccu.append(-1)\n",
    "\n",
    "    else:\n",
    "        # else append a placeholder to allow DataFrame construction later\n",
    "        TrainAccu.append(-2)\n",
    "        ValAccu.append(-2)\n",
    "        TestAccu.append(-2)\n",
    "        TrainCount.append(0)\n",
    "        ValCount.append(0)\n",
    "        TestCount.append(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "     DOLocationID  TrainAccu   ValAccu  TestAccu  TrainCount  ValCount  \\\n0               1   0.534913  0.537143  0.540698         802       175   \n1               2   1.000000 -1.000000 -1.000000           4         0   \n2               3   1.000000 -1.000000 -1.000000           2         0   \n3               4   0.937030  0.911628  0.888350        1064       215   \n4               5   1.000000 -1.000000 -1.000000           1         0   \n..            ...        ...       ...       ...         ...       ...   \n258           259   0.657895  0.200000  0.400000          38         5   \n259           260   0.549518  0.491304  0.452915        1141       230   \n260           261   0.512915  0.434211  0.412935        1084       228   \n261           262   0.744015  0.761682  0.748768        1086       214   \n262           263   0.555150  0.478873  0.388626        1097       213   \n\n     TestCount  \n0          172  \n1            0  \n2            0  \n3          206  \n4            0  \n..         ...  \n258          5  \n259        223  \n260        201  \n261        203  \n262        211  \n\n[263 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DOLocationID</th>\n      <th>TrainAccu</th>\n      <th>ValAccu</th>\n      <th>TestAccu</th>\n      <th>TrainCount</th>\n      <th>ValCount</th>\n      <th>TestCount</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.534913</td>\n      <td>0.537143</td>\n      <td>0.540698</td>\n      <td>802</td>\n      <td>175</td>\n      <td>172</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.937030</td>\n      <td>0.911628</td>\n      <td>0.888350</td>\n      <td>1064</td>\n      <td>215</td>\n      <td>206</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>1.000000</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>258</th>\n      <td>259</td>\n      <td>0.657895</td>\n      <td>0.200000</td>\n      <td>0.400000</td>\n      <td>38</td>\n      <td>5</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>259</th>\n      <td>260</td>\n      <td>0.549518</td>\n      <td>0.491304</td>\n      <td>0.452915</td>\n      <td>1141</td>\n      <td>230</td>\n      <td>223</td>\n    </tr>\n    <tr>\n      <th>260</th>\n      <td>261</td>\n      <td>0.512915</td>\n      <td>0.434211</td>\n      <td>0.412935</td>\n      <td>1084</td>\n      <td>228</td>\n      <td>201</td>\n    </tr>\n    <tr>\n      <th>261</th>\n      <td>262</td>\n      <td>0.744015</td>\n      <td>0.761682</td>\n      <td>0.748768</td>\n      <td>1086</td>\n      <td>214</td>\n      <td>203</td>\n    </tr>\n    <tr>\n      <th>262</th>\n      <td>263</td>\n      <td>0.555150</td>\n      <td>0.478873</td>\n      <td>0.388626</td>\n      <td>1097</td>\n      <td>213</td>\n      <td>211</td>\n    </tr>\n  </tbody>\n</table>\n<p>263 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile the statistics into a DataFrame\n",
    "accuracy_by_location = pd.DataFrame({'DOLocationID': id,\n",
    "                                     'TrainAccu': TrainAccu,\n",
    "                                     'ValAccu': ValAccu,\n",
    "                                     'TestAccu': TestAccu,\n",
    "                                     'TrainCount': TrainCount,\n",
    "                                     'ValCount': ValCount,\n",
    "                                     'TestCount': TestCount})\n",
    "accuracy_by_location"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Export statistics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# create directory to store models results\n",
    "output_relative_dirs = ['../data/curated/final_model_data']\n",
    "\n",
    "# check if it exists as it makedir will raise an error if it does exist\n",
    "for output_relative_dir in output_relative_dirs:\n",
    "    if not os.path.exists(output_relative_dir):\n",
    "        os.makedirs(output_relative_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "accuracy_by_location.to_csv('../data/curated/final_model_data/logreg.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}